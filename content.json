{"posts":[{"title":"About Me","text":"[🔨 Pinned] I am currently a Ph.D. student at Hong Kong University of Science and Technology (HKUST), under the guidance of Prof.Charles Zhang. My current research interests focus on program analysis and theorectial computer science. Before that, I received my bachelor’s degree in computer science from Shanghai Jiao Tong University. During my undergraduate study, I worked closely with the following professors: Biaoshuai Tao, Hongfei Fu, Qinxiang Cao and Yuhao Zhang. Thanks for their patient guidance. contact: jsongbk@cse.ust.hk [Google Scholar] | [Publication] | [Blogs] | [Github] Research Interests My research interests include static program static analysis and theoretical computer science problems. More recenltly, I have been studying problems in: Large-scaled Language Model (LLM) for static analysis Scalable static analysis tool Development Loop Invariant Generation Selected Awards Hong Kong PhD Fellowship Scheme (2023) Zhiyuan Outstanding Student Scholarship in SJTU (2023) [link]","link":"/2023/02/03/About-Me/"},{"title":"Reading List of Jiaxin","text":"I will maintain a list of blogs or official document interesting to me here. 1. LLVM Kaleidoscope: Implementing a Language with LLVM Writting a LLVM Pass How to Parse LLVM IR Line by Line? 2. Program Analysis Linear Invariant Generation Non-linear loop invariant generation using Gröbner bases [POPL’04] [link] In this paper, the authors propose an method to generate polynomial loop invariants. The invariant problem eta(l) /\\ theta |= eta(l') can be also regarded as determining whether eta(l') \\in Ideal(eta(l), theta). They use some heuristic methods based on the Gröbner bases. For example, they introduce new parameter \\lambda and determine whether \\lambda*NF(eta(l)) = NF(eta(l')). A Singular Introduction to Commutative Algebra [link], especially, sec 1.7 Strong Grobner Bases for Polynomials over a Prinpal Ideal Ring [link] New developments in the theory of Groebner bases and applications to formal verification [link] Accerlating Program Analysis Split input: Input Splitting for Cloud-Based Static Application Security Testing Platforms (ICSE’ 22) Constraint Solving z3 playground z3 rust, z3 rust crate api Program Analysis of Rust Rust Lifetime [link] Visualization of Lifetime Constraints in Rust [link] C2Rust: Ownership Analysis [link] SPrinter: A Static Checker for Finding Smart Pointer Errors in C++ Programs [link] Detecting Memory-Related Bugs by Tracking Heap Memory Management of C++ Smart Pointers [link] Translating C to Safer Rust (OOPSLA’21) [link] 3. Fair Division Group Fairness Kneser graph: Discrepency theory: Almost Envy-Freeness for Groups: Improved Bounds via Discrepancy Theory Minimize the number of queries when calculating fair allocations Fairly Allocating Many Goods with Few Queries The Query Complexity of Cake Cutting Almost envy-free allocations with connected bundles 4. Blockchain Gas Cost Bound Analysis Developing Cost-Effective Blockchain-Powered Applications: A Case Study of the Gas Usage of Smart Contract Transactions in the Ethereum Blockchain Platform Data-Driven Loop Bound Learning for Termination Analysis Computing Exact Loop Bounds for Bounded Program Verification Exact and Linear-Time Gas-Cost Analysis","link":"/2023/02/13/Useful-Documents-and-Blogs/"},{"title":"Paper Reading: Goshawk","text":"This is a paper reading report of the paper “Goshawk: Hunting Memory Corruptions via Structure-Aware and Object-Centric Memory Operation Synopsis” in S&amp;P’2022. They mainly study how to detect the memory management function (MM) (e.g., malloc(), free(), kzmalloc()). They found most of the memory management functions can be determined according to their function name and propose a new approach to identify MM functions with the help of a trained NLP model. 1. Motivation Why we need to identify the MM functions? In Figure 1, the authors provide a motivated example, where there is a double-free bug caused by user-defined memory management functions. In function hvfb_probe(), it invokes function hvfb_getmem(), which could free the pointer info-&gt;apertures. However, it ignores this fact and frees this pointer again later. For a static analysis tool, for example, KLEE, it just knows free() and kfree() are deallocators. So when encountering the call of function hvfb_getmem(), it does not know that function could potentially free the pointer info-&gt;apertures. It will go into that function and then continue searching …, and finally encounter the call of kfree(). Such analysis is time-consuming. If we are able to know hvfb_getmem() may frees info-&gt;apertures, we could have skipped unfolding hvfb_getmem(). 2. Overview of the paper The above figure gives an overview of this paper: Given the C source codes and the prototypes of all the functions, they use a pre-trained NLP model ($\\tau:$ function name $\\rightarrow [0, 1]$) to determine whether a function is an allocator/deallocator or not. The higher of the value of $\\tau(f)$, the higher the probability $f$ is an allocator/deallocator. Set the threshold as $\\theta$. Next, the functions with a higher belief than $\\theta$ will be included in the set of MM candidate. Next, suppose the input official MM functions $\\mathcal{M}$ = {free, malloc, kmalloc, $\\ldots$}. The authors design a data-flow analysis algorithm to validate whether a candidate is an MM function. Finally, they provide a Memory Operation Synopsis(MOS) for verified MM function. The MOS is an MM behaviors summary. With the help of these summaries, they further do some bug detection. 3. Advantages and Disadvantages 4. Implementation Details To determine whether a MM function candidate is an real MM function. The authors design a data-flow based algorithm. After reading their implementation, I summarize their algorithm for detecting allocators as follows: Denote the call graph as $G = (V, E)$, where $V$ contains all the methods and $E$ contains all the call-edges. Specially, $(f,g)\\in E$ if method $f$ calls method $g$. For an method $f$, we use $\\mathcal{A}(f)$ to represent the set of its callees. Perform the NLP model and get a belief $\\tau(f) \\in [0,1]$ for each method $f$ of $V$. Set the threshold as $\\theta$ and collect the set of methods with a belief no more than $\\theta$: $\\mathcal{C} \\triangleq$ ${f: \\tau(f) \\ge \\theta}$. Extract a subset of methods $\\mathcal{S}$ from $\\mathcal{C}$. These functions satisfy the following requirements and are named strong belief allocation functions. For each method $f\\in \\mathcal{S}$, the return type of $f$ is a pointer, there is no pointer within the parameters of $f$, $\\tau(f) \\ge \\theta$, Exact one of its callees must belongs to $\\mathcal{S}$, If the return type is a struct pointer, then $f$ should not have more than two callees belonging to $\\mathcal{S}$. In addition, they also include the official allocators into the set $\\mathcal{S}$. Although these requirements look a litte weird…, I get they want to first pick some candidates that have high probabilities to be MM functions. Next, for the all candidates of $\\mathcal{C}$, they perform the following check: [Check 1]: Check whether a candidate $f$ invokes a strong belief allocation function of $\\mathcal{S}$. Otherwise or $f\\in \\mathcal{S}$, kick $f$ off from $\\mathcal{C}$. [Check 2]: For a candidate $f$, if it directly invokes a strong belief allocation function $g$ of $\\mathcal{S}$, then go to the third check. Otherwise, recursively traverse all of its callees and perform the second check. If one of its callees is included in $\\mathcal{S}$, then further perform the third check. [Check 3]: Denote the call of $g$ within $f$ by ret &lt;- g(...). If $ret$ occurs in the return values, then include $f$ into $\\mathcal{S}$. Otherwise, check wether $ret$ occurs in the parameters of $f$ (it means $f$ return the allocated memory via passing parameters).","link":"/2023/09/03/Paper-Reading-Goshawk/"},{"title":"SSA Transformation of Move Stackless Bytecodes","text":"最近在做有关Move Prover的开发。这两周主要负责将Move Stackless Bytecode转换为single staic assignment(SSA)格式。想简单写一篇文章记录一下具体实现流程。 1. Source Codes SSA源代码可以在fork出的repo里最新的两个commit获取。 Usage 1$ move prove -p [move dir] -- -ssa #enable ssa transformation Example: 1234IfCondition├── Move.toml└── sources └── main.move 其中main.move的内容如下： 1234567891011module 0xCAFE::BasicCoin { public fun f1(x1: u8) :u8 {x1} public fun if1(x1: u8, i: u8) :u8 { if (i &gt; 0) { x1 = 1; }; f1(x1) }} 执行 1$ move prove -p IfCondition -- -dump-bytecode 可以看到原始的bytecode如下: 123456789101112131415161718192021public fun BasicCoin::if1($t0|x1: u8, $t1|i: u8): u8 { var $t2: u8 var $t3: u8 var $t4: bool var $t5: u8 var $t6: u8 var $t7: u8 0: $t2 := move($t1) 1: $t3 := 0 2: $t4 := &gt;($t2, $t3) 3: if ($t4) goto 4 else goto 8 4: label L1 5: $t5 := 1 6: $t0 := $t5 7: goto 8 8: label L0 9: $t6 := move($t0) 10: $t7 := BasicCoin::f1($t6) 11: return $t7} 执行 12$ move prove -p IfConidtion -- -ssa 输出的经ssa转换后的bytecode如下： 12345678910111213141516171819202122public fun BasicCoin::if1($t0|x1: u8, $t1|i: u8): u8 { var $t2: u8 var $t3: u8 var $t4: bool var $t5: u8 var $t6: u8 var $t7: u8 var $t8: u8 var $t9: u8 0: $t2 := move($t1) 1: $t3 := 0 2: $t4 := &gt;($t2, $t3) 3: if ($t4) goto 4 else goto 7 4: label L1 5: $t5 := 1 6: $t9 := $t5 7: label L0 8: $t8 := phi($t0, $t9) 9: $t6 := move($t8) 10: $t7 := BasicCoin::f1($t6) 11: return $t7} 2. Main Algorithm 主要的算法实现参考了 [1] 中基于dominator的SSA construction算法。大致流程分为两步： (Phi Insertion): 先计算出控制流图中需要插入Phi函数的位置。 (Variable Renaming): 对源代码中定义和使用的变量做重命名。 3. Implementation 目前move-prover在stackless bytecode这个阶段进行的分析，都是以FunctionProcessor的形式给上层调用提供接口。其中FunctionProcessor::Process()方法，在拿到所有函数的signature，环境信息，以及某个具体待分析函数的具体内容后，对待分析的函数内容做一些变换/分析。 move-prover/src/bytecode/src/function_target_pipeline.rs12345678910111213pub trait FunctionTargetProcessor { /// Processes a function variant. Takes as parameter a target holder which can be mutated, the /// env of the function being processed, and the target data. During the time the processor is /// called, the target data is removed from the holder, and added back once transformation /// has finished. This allows the processor to take ownership on the target data. fn process( &amp;self, _targets: &amp;mut FunctionTargetsHolder, _fun_env: &amp;FunctionEnv&lt;'_&gt;, _data: FunctionData, ) -&gt; FunctionData { unimplemented!() } 出于与move-prover后端代码开发保持一致，并且能让导出的SSA codes可以用上目前已有的分析的目的，我将SSA转化也实现在了FunctionTargetProcessor内。但其实注意到，process的返回值只是原本的data，这是因为，经过SSA转换后的bytecode和原本的bytecode其实是两套，目前还不确定会不会影响一些built-in的analysis的正常执行。所以在这里只是把转换后的结果打印出来了，并没有实际返回。 move-prover/src/bytecode/src/ssa_analysis.rs1234567891011121314151617impl FunctionTargetProcessor for SSAConstructionProcessor { fn process( &amp;self, _targets: &amp;mut FunctionTargetsHolder, func_env: &amp;FunctionEnv, data: FunctionData, ) -&gt; FunctionData { let original_data = data.clone(); let mut define_once_vars: Vec&lt;TempIndex&gt; = vec![]; let data_with_phi = Self::insert_phi_functions(data, func_env, &amp;mut define_once_vars); let data_after_renaming = Self::rename_variables(data_with_phi, func_env, &amp;mut define_once_vars); let func_target = FunctionTarget::new(func_env, &amp;data_after_renaming); println!(&quot;{}&quot;, format!(&quot;{func_target}&quot;)); original_data } 3.1 Add Phi() to the Definition of Bytecodes SSA和原始bytecode的主要区别在于Phi函数的引入。我在原始bytecode的定义中，加入了一条$v_s = \\phi\\left( [v_{t,1}, \\ldots, v_{t, k}], v\\right)$。其中$v_s$表示由$\\phi$函数定义的新寄存器编号，$[v_{t,1}, \\ldots, v_{t, k}]$表示在此处合并的所有变量定义，$v$表示这些新变量在原始bytecode中对应的下标。 move-prover/src/bytecode/src/sackless_bytecode.rs123456pub enum Bytecode { Assign(AttrId, TempIndex, TempIndex, AssignKind), ... Phi(AttrId, TempIndex, Vec&lt;TempIndex&gt;, TempIndex), // New added} Note: 实际上，尽管bytecode中目前添加了phi这条语句，在其他分析中仍然用的是旧的bytecode。即使在语法上不得不处理phi，也都采取跳过的办法。 3.2 Graph Algorithm API 目前在mover-prover里，提供了两种版本的图算法，一种是move-prover/src/bytecode/src/graph.rs内提供的一些general的图算法的实现（dominator计算，immediate dominance tree的构建），另外一种是在move-prover/src/bytecode/src/stackless_control_flow_graph.rs内提供了一些control flow graph上的算法（如何从线性的bytecode转成control flow graph，如何打印等等）。 在拿到一个StacklessControlFlowGraph后，如果想在上面跑一些图算法，需要先将其转为一个graph，具体代码如下： move-prover/src/bytecode/src/ssa_analysis.rs123456789101112131415fn create_graph_from_cfg(cfg: &amp;StacklessControlFlowGraph) -&gt; Graph&lt;BlockId&gt; { let entry: BlockId = cfg.entry_block(); let nodes: Vec&lt;BlockId&gt; = cfg.blocks(); let edges: Vec&lt;(BlockId, BlockId)&gt; = nodes .iter() .flat_map(|x| { cfg.successors(*x) .iter() .map(|y| (*x, *y)) .collect::&lt;Vec&lt;(BlockId, BlockId)&gt;&gt;() }) .collect(); let graph = Graph::new(entry, nodes, edges); graph} 和dominator相关的计算都实现在move-prover/src/bytecode/src/graph.rs的DomRelation内。它在拿到一个图之后，对结点进行重新编号。具体来说，假如输入的图的所有结点为$[a, b, c]$，DomRelation会内部维护一个映射，将$[a, b, c]$映射到$[0, 1, 2]$。其中主要用到的API接口的介绍如下： pub fn is_dominated_by(&amp;self, x: T, y: T) -&gt; bool 判断结点x是否被结点y所dominate。 pub fn postorder_visit(&amp;mut self, graph: &amp;Graph&lt;T&gt;) 对输入的图做后续遍历，并初始化内部维护的映射。 pub fn depth_first_traverse(&amp;self, graph: &amp;Graph&lt;T&gt;) -&gt; Vec&lt;T&gt; 对immediate dominante tree做深度优先搜索，并返回遍历结果。 pub fn compute_dominance_frontier(&amp;mut self, graph: &amp;Graph&lt;T&gt;) 计算所有结点对应的dominance frontier。 3.3 Phi Insertion Phi insertion的主要实现大致如下： 先取出原始的data: FunctionData内的所有bytecode，并生成对应的control flow graph， 1234let old_code = std::mem::take(&amp;mut builder.data.code);let cfg = StacklessControlFlowGraph::new_forward(&amp;old_code);let graph = Self::create_graph_from_cfg(&amp;cfg);let dom_frontier = graph.compute_dominance_frontier(); 执行[1]中的Phi insertion算法，计算出所有需要插入Phi的位置在bytecode中的offset 逐句遍历bytecode，并一条一条emit到data内， 12345678910111213for (offset, bc) in old_code.into_iter().enumerate() { let co_offset = offset as CodeOffset; if phi_insertion_records.contains_key(&amp;co_offset) { builder.emit(bc); let variable_vec = phi_insertion_records.get_mut(&amp;co_offset).unwrap(); for v in variable_vec { let new_attrid = builder.new_attr(); builder.emit(Bytecode::Phi(new_attrid, v.clone(), vec![], v.clone())) } } else { builder.emit(bc); }} 3.4 Variable Renaming Variable renaming的主要实现大致如下： 先取出原始的data: FunctionData内的所有bytecode，并生成对应的control flow graph。 初始化每个寄存器的reaching definition， 123456for i in 0..parameter_count { reaching_def_map.insert(i, (i, cfg.entry_block()));}for i in parameter_count..local_count { reaching_def_map.insert(i, (usize::MAX, cfg.entry_block()));} DFS遍历immediate dominance tree，并对每个block内的指令做renaming, 123456789101112let dom_tree_dfs_res = dom_relation.depth_first_traverse(&amp;graph);for block_id in dom_tree_dfs_res { Self::rename_variables_within_block( &amp;mut builder, &amp;mut old_code, &amp;dom_relation, &amp;mut reaching_def_map, &amp;cfg, &amp;block_id, define_once_vars, );} 4. Limitation 目前虽然实现里，经过SSA转化之后，得到的形式是FunctionData的格式。但目前还没有经过测试，看是否和其他分析兼容。 在SSA转化过程中，并没有处理Prop Reference [1]. Sec 3. SSA book.","link":"/2023/04/17/SSA-Transformation-of-Move-Stackless-Bytecodes/"},{"title":"Infer Buffer Overrun (II) - Abstract Domain","text":"Abstract In this blog, we will take a further look at the abstract domain within the buffer overrun checker (inferbo), including intervals, bounds, locations, and memory model. Inferbo uses the conventional program analysis techinque of intervals for the range of index values and buffer sizes. Infers works on the intervals [low, high], where the two bounds are both symbolic [1]. Moreover, the bounds can also contain some linear arithmetic with min/max operators. 1. Bound Here is the formal definition of bound within inferbo. It is implemented in the file infer/src/bufferoverrun/bounds.ml. $$ \\mathbf{LinearSym} \\triangleq \\mathbf{Sym} \\rightarrow \\mathbb{Z} $$ $$ \\mathbf{Bound} \\triangleq \\pm \\infty \\ |\\ \\mathbb{Z} + \\mathbf{LinearSym} \\ |\\ \\mathbb{Z} +\\max/\\min(\\mathbb{Z}, \\mathbf{LinearSym}) $$ $$ |\\ \\min/\\max(\\mathbf{Bound}, \\mathbf{Bound})\\ |\\ \\mathbb{Z} + \\mathbf{Bound} \\times \\mathbf{Bound}, $$ where $\\mathbf{Sym}$ represents symbols (e.g., variables occurred in the program), and $\\mathbf{LinearSym}$ represents a linear composition of symbols. Within the module Bound, infer also offers some tool functions. Among them, pp specifies the output format; of_big_int converts an int number n to Linear n; is_symbolic determines whether there is a symbol within a bound; le gives an rough comparation between two bounds. However, it only defines orders for only straightforward cases. For some comparation like $1+ x \\overset{?}{&lt;} 1+ y$, it can not determine the result and just return false; neg takes a bound to be negative; exact_min computes the exact minimum value of two bounds. For example, $\\mathrm{exact\\ min}(c1, c2 + x) = \\min(c2, \\min(c2 - c1, x))$. underapprox_min gives a lower bound of the minimum value of two bounds; overapprox_min gives an upper bound of the minimum value of two bounds; plus_u (plus_l) sums two bounds as upper bounds (lower bounds); 2. Interval The interval is defined in the module ItvPure of the file infer/src/bufferoverrun/itv.ml. Each interval is composed of a lower bound lb and an upper bound ub. 3. Memory Model Similar to the heap model in separation logic, the memory within infer buffer overrun checker is modeled as $\\mathbf{Mem}: \\mathbf{Loc} \\rightarrow \\mathbf{MVal}$, where $\\mathbf{Loc}$ represents either a stack location or a heap location location and $\\mathbf{MVal}$ represents the symbolic value stored at that location. 3.1 Location In infer/src/bufferoverrun/absLoc.ml, Loc is defined as follows, 1234567891011121314151617181920module Allocsite = struct type t = | Unknown | Symbol of Symb.SymbolPath.partial | Known of { proc_name: string ; caller_pname: Procname.t option ; node_hash: int ; inst_num: int ; dimension: int ; represents_multiple_values: bool ; path: Symb.SymbolPath.partial option } | LiteralString of stringendmodule Loc = struct type prim = Var of Var.t | Allocsite of Allocsite.t [@@deriving compare, equal] type t = prim BoField.t [@@deriving compare, equal] ...end Allocite is defined as the location of an instruction that allocates memory. Loc has two constructors. The first one represents a variable or a register while the second one represents an allocated memory location. Specifically, $$ \\mathbf{prim} \\triangleq \\mathbf{Var}\\ |\\ \\mathbf{Allocsite}, \\mathbf{Loc} \\triangleq \\mathbf{prim}\\ |\\ \\mathbf{prim}.field\\ |\\ *\\mathbf{prim} $$ 3.2 Value","link":"/2023/02/04/Infer-Buffer-Overrun-II/"},{"title":"Infer Buffer Overrun (I) - Build and Run","text":"Abstract Hello, everyone! This is a series of blogs. I want to discuss the structure of the buffer overrun checker of infer, a static analysis tool developed by Facebook. Now, I will firstly discuss how to build it and run checkers within it. 1. How to build infer? The official document both offers methods to get binary version and directly build from source codes. Building from source codes is a time-consuming job. So if you do not need to modify the source codes, you could just install the binary relases. 1.1 Get the binary version On Macos, $ brew install infer On Linux, to install infer with VERSION=0.XX.Y, $ VERSION=0.XX.Y; \\ curl -sSL &quot;https://github.com/facebook/infer/releases/download/v$VERSION/infer-linux64-v$VERSION.tar.xz&quot; \\ | sudo tar -C /opt -xJ &amp;&amp; \\ sudo ln -s &quot;/opt/infer-linux64-v$VERSION/bin/infer&quot; /usr/local/bin/infer 1.2 Build from source codes I have tried to build infer on arm based macos. Unfortunately, I could not build clang on M1-chip mac. Hence, I only use infer to check java codes on macos. Nevertheless, if you still would like to use infer on macos, you could choose the docker image I made. On Ubuntu, please first install the packages required. The details can be found at here. Then, follow the below steps, $ git clone https://github.com/facebook/infer.git $ cd infer $ ./build-infer.sh clang # Compile cpp $ sudo make install # ...or, alternatively, install Infer into your PATH $ export PATH=`pwd`/infer/bin:$PATH Note that, infer will default build a java version. Hence, if you do not want to build the cpp version, just replace the third command with ./build-infer.sh. The common error I met is ‘fail to ld’ and ‘not enough space on the disk’. The reasons and solutions are as follows: The first one is because clang is compiled in parallel. Hence, it would produce many intermediate files, making the swap and memory full. To avoid parallel compilation or reduce the number of threads, you could change the value of JOBS to 1 in the script facebook-clang-plugins/clang/setup.sh. The second one is because you may repeatly build infer several times. Therefore, there will be several unbuilt clang within /tmp/. You could just delete the previous files or restart your machine. On Macos, to build java-based infer, first install the required packaegs. $ brew install autoconf automake cmake opam pkg-config sqlite gmp mpfr java Then, follow the same steps as Linux. 2. Usage of Infer As the official document said, there are two phases of infer: capture and analyze. Within the first phase, infer compiles the source files and generates some temporary files for further analysis. All the intermediate files are stored in the directory infer-out/. After that, infer takes the files within infer-out/ as input and then, analyzes them and report errors. 2.1 How to run infer? For instance, to analyze a cpp source file hello.cpp, $ infer capture -- clang hello.cpp $ infer analyze -- clang hello.cpp # ... or, alternatively, just run the following command instead of the above two $ infer run -- clang hello.cpp If you do not specify checkers within the above command, infer will only do some basic checks. To activate some particular checkers, please add specific option, like --bufferoverrun (checking whether there exists a buffer ovrrun bug), --cost (computing the time complexity of functions and methods), etc. 2.2 How to find the trace triggering bugs? Infer collects the trace that triggers a bug. To see the trace, just run infer explore after running the command within 2.1 and write the number of issue. $ infer explore 1 # 1 can be replaced by other issue number 2.3 Tips for debugging Infer offers a convenient analysis framework for programmers to develop multiple checkers. It uses the technique of abstract interpretations, in which there is an abstract domain, and the checker computes the abstract value before and after running each instruction. A direct way to debug infer is to print the abstract values to the console. We can observe that, within most modules, there is a function called pp. This function specifies the format for printing this data structure. To print it, please plug this function as an argument to Logging.debug_dev. For example, if instr is a variable with type Sil.instr, to print it, just insert the following code into the source codes 1Logging.debug_dev &quot;Instr: %a&quot; Sil.instr.pp instr","link":"/2023/02/04/Infer-Buffer-Overrun-I/"},{"title":"Hello World","text":"Welcome to my website! This is your very first post.","link":"/2023/02/03/hello-world/"}],"tags":[{"name":"infer","slug":"infer","link":"/tags/infer/"},{"name":"static analysis","slug":"static-analysis","link":"/tags/static-analysis/"},{"name":"Security","slug":"Security","link":"/tags/Security/"},{"name":"Static Analysis","slug":"Static-Analysis","link":"/tags/Static-Analysis/"},{"name":"Paper Reading","slug":"Paper-Reading","link":"/tags/Paper-Reading/"},{"name":"Program Analysis","slug":"Program-Analysis","link":"/tags/Program-Analysis/"},{"name":"SSA","slug":"SSA","link":"/tags/SSA/"}],"categories":[{"name":"static anlysis","slug":"static-anlysis","link":"/categories/static-anlysis/"},{"name":"Static Analysis","slug":"Static-Analysis","link":"/categories/Static-Analysis/"},{"name":"Program Analysis","slug":"Program-Analysis","link":"/categories/Program-Analysis/"}],"pages":[{"title":"","text":"Conference Paper Fair Division with Allocator’s Preference [WINE’2023] [📄] Xiaolin Bu, Zihao Li, Shengxin Liu*, Jiaxin Song, Biaoshuai Tao (alphabetical author ordering). Fair Division with Prioritized Agents [AAAI’2023] [📄] [bib] Xiaolin Bu, Zihao Li, Shengxin Liu*, Jiaxin Song, Biaoshuai Tao (alphabetical author ordering). Scalable Linear Invariant Generation with Farkas’ Lemma [OOPSLA’2022] [📄] Hongming Liu, Hongfei Fu*, Zhiyong Yu, Jiaxin Song, Guoqiang Li. Journal On Existence of Truthful Fair Cake Cutting Mechanisms [Artifical Intelligence Journal] [📄] Xiaolin Bu, Jiaxin Song, Biaoshuai Tao (alphabetical author ordering). Working Papers On the Complexity of Maximizing Social Welfare within Fair Allocations of Indivisible Goods [📄] Xiaolin Bu, Zihao Li, Shengxin Liu*, Jiaxin Song, Biaoshuai Tao (alphabetical author ordering). Towards Denotational-semantics-based Compiler Correctness Verification Jiaxin Song, Zhang Cheng, Qinxiang Cao*.","link":"/publications/index.html"},{"title":"About","text":"I am currently a Ph.D. student at Hong Kong University of Science and Technology (HKUST), under the guidance of Prof.Charles Zhang. Before that, I received my bachelor’s degree in computer science from Shanghai Jiao Tong University. During my undergraduate study, I worked closely with Biaoshuai Tao, Hongfei Fu, Qinxiang Cao and Yuhao Zhang. Thanks for these professors’ patient guidance. Teaching Assistant Algorithm Design and Analysis (SJTU), 2022 Spring. Linear and Convex Optimization (SJTU), 2022 Fall. Research Interests My research interests include program static analysis and theoretical computer science problems. More recenltly, I have been studying problems in: Compilation Optimization GPGPU Online Fair Division In 2022 summer, we organized a paper reading group for discussing recent algorithm papers. The web page is here. If you have similar research interests to me, please don’t be shy to contact me. Awards Zhiyuan Honor Scholarship, SJTU (2019 - 2022, ¥5k/year) Huatai Scholarship, SJTU (2022, ¥1w/year) Class B Scholarship, SJTU (2021, 2022, ¥1k/year) Class C Scholarship, SJTU (2020, ¥500/year) Chenhao Alumni Scholarship, SJTU (2021, ¥5k/year) Contact mail: sjtu_xiaosong@sjtu.edu.cn","link":"/about/index.html"}]}